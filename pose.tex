%-----------------------------------------------------------------------------------------------
\chapter{Pose estimation}\label{sect:pose}
%-----------------------------------------------------------------------------------------------

The goal of this project is to calculate camera pose using a fiducial marker.
To achieve this, a wide range of problems have to be solved including but not limited to marker design, detection, pose calculation.
This chapter will focus on 3D pose estimation problem.
First, it's mathematical formulation will be presented.
Later some solutions to the problem will be summarised and compared.
Based on this comparison, an algorithm will be selected for use in this project.

Taking photos with a camera can be thought of as mapping 3D points from scene being observed to the image plane of the camera.
This mapping depends on a number of parameters, some of witch is tied to the camera, others depend on the viewpoint and angle.
Based on these parameters, a \textit{perspective projection model} can be constructed.
Mathematically, the model can described by a $P$ projection matrix.
It is a $3*4$ matrix, which gives the image point\footnote{Determined up to a scale factor} for any given world point in homogeneous coordinates.
\begin{equation}
	P = K [R|T]
	\label{eq:projMatrix}
\end{equation}
The $P$ matrix can be constructed as shown in \eqref{projMatrix}.

$K$ is a $3*3$ matrix describing the \textit{intrinsic camera parameters} or \textit{camera model}.
These parameters depend only the internals of the camera, thus are independent from the orientation or position.
Once these are measured for a camera, they can be reused later.
Some models use more variables to describe the internal workings of the camera, others are more simple.
The model used in this work is summarized by the camera matrix described in \eqref{intrinsicParams}.
\begin{equation}
	K =
	\begin{bmatrix}
		f_x & \gamma & u_0 \\
		0   & f_y    & v_0 \\
		0   & 0      & 1
	\end{bmatrix}
	\label{eq:intrinsicParams}
\end{equation}
The notation of the model is the following: $f_x$ and $f_y$ denote the focal lengths of the camera on the $x$ and $y$ axis, while $(u_0,v_0)$ is the principal point.
The principal point is the image point where the optical axis intersects with the image plane.
The parameter $\gamma$ is the skew of the camera, which will be neglected in this work, $\gamma = 0$ will be used.
The elements of matrix $K$, the intrinsic camera parameters are determined in the process of \textit{camera calibration}.

The other part of the projection matrix, $[R | T]$, describe the position and orientation of the camera in the world coordinate system.
These are called \textit{extrinsic parameters}, and depend on the current configuration (position) of the camera.
The matrix is constructed as shown in \eqref{extParams}.
\begin{equation}
	[R | T] =
	\begin{bmatrix}
		r_{11} & r_{12} & r_{13} & t_1\\
		r_{21} & r_{22} & r_{23} & t_2\\
		r_{31} & r_{32} & r_{33} & t_3\\
	\end{bmatrix}
	\label{eq:extParams}
\end{equation}
It is made up of two separate parts: $R$ describes the orientation, while $T$ the translation with respect to the origin of the world coordinate system.
These parameters are only valid while the camera remains stationary.
The calculation of matrix $[R|T]$ is the process of \textit{camera pose estimation}, which is also known as the \textit{perspective-n-point problem}.
The pose of a calibrated camera can be estimated using $n$ 3D points in the world frame and their corresponding $n$ points in the image plane.
The camera pose has 6 DOF: the rotation (roll, pitch, and yaw) and the translation.
In \eqref{extParams}, the $R$ is the rotation matrix, and $T$ is the translation vector.

In the next section some solutions to the PnP problem will be presented.

%-----------------------------------------------------------------------------------------------
\section{Pose Estimation Algorithms}
%-----------------------------------------------------------------------------------------------

There have been many solutions to the perspective-n-point problem.
These varied in performance, accuracy and principle.
Some only gave solutions to the case of $n=3$, which is the simplest solution computationally, but is also very error prone. 
Others solved the problem for any number of point pairs, but required that the points are not coplanar.
Still another class of algorithms worked on coplanar points.

% TODO: introduction finalise

%-----------------------------------------------------------------------------------------------
\subsection{EPnP}
%-----------------------------------------------------------------------------------------------

An efficient, non-iterative solution to the problem was described in \cite{Lepetit2008}.
The algorithm has a complexity of $O(n)$ for $n\geq4$, which is substantially more efficient than it's rivals.
The EP$n$P algorithm is more accurate than most non-iterative solutions, and it's also much faster than the iterative algorithms.

EP$n$P solves the pose estimation problem for $n\geq3$ point correspondences.
The core concept of the solution is that each $n$ \textit{reference point}\footnote{Points in the world frame} can be expressed as a weighted sum of 4 \textit{virtual control points}\cite{Lepetit2008} (actually, for the planar reference points, 3 virtual control point are enough).
This way the coordinates of these control points become the unknown variables of the problem.
The camera pose is later calculated from the control points.

A short summary of the process will be presented here, using the notation of the original paper\cite{Lepetit2008}.
First, the $n$ reference points in world coordinates ($p_i^w$) and their corresponding image reference points ($p_i^c$) are expressed as linear combinations of the virtual control points ($c_j^w, c_j^c$).
\begin{align}
	p_i^w = \sum_{j=1}^{4} \alpha_{ij} c_j^w \\ 
	p_i^c = \sum_{j=1}^{4} \alpha_{ij} c_j^c \\
	\sum_{j=1}^{4} \alpha_{ij} = 1
\end{align}
Note that the weights are normalised per reference point.
Also, all points are represented with homogeneous coordinates.

EP$n$P only calculates the extrinsic parameters of the projection.
It requires the intrinsic camera matrix to work, which will be noted with $K$.
With this in mind, the relationship between the image reference points and the world reference points can be written as
\begin{equation}
	s_i p_i^c = K \sum_{j=1}^{4} \alpha_{ij} c_j^c,
	\label{eq:controlPointProj}
\end{equation}
where $s_i$ is a scalar projective parameter.

The homogeneous coordinates of the image control points will be noted as follows.
\begin{equation}
	c_j^c = 
	\begin{bmatrix}
		x_j^c & y_j^c & z_j^c
	\end{bmatrix}^T
\end{equation}
With this notation, \eqref{controlPointProj} can be rearranged into the following form for each reference point.
\begin{align}
	\sum_{j=1}^{4} \alpha_{ij} f_x x_j^c + \alpha_{ij} (u_0 - u_i) \\
	\sum_{j=1}^{4} \alpha_{ij} f_y y_j^c + \alpha_{ij} (v_0 - v_i) 
\end{align}

Using the above two equations for each reference point, a homogeneous linear equation system $Mx = 0$ can be formed for the control points.
The $x$ vector is defined by
\begin{equation}
x = 
	\begin{bmatrix}
		{c_1^c}^T & {c_2^c}^T & {c_3^c}^T & {c_4^c}^T
	\end{bmatrix}^T,
\end{equation}
and the solution for control points will lie in the kernel of $M$.
Solving the system with the SVD method, the solution is expressed as:
\begin{equation}
	x = \sum_{i=1}^{N} \beta_i v_i
\end{equation}
Where $N$ is the number of the singular values of $M$ and $v_i$ is corresponding singular vector.

Using the solution obtained for the control points, the P3P problem is solved for the pose.
It is proven in \cite{Lepetit2008} that the $R$ and $T$ matrices minimise the reprojection error between the world reference points and their corresponding image reference points.

%-----------------------------------------------------------------------------------------------
\subsection{An Iterative Solution}
%-----------------------------------------------------------------------------------------------

%-----------------------------------------------------------------------------------------------
\subsection{Robust Pose Estimation from a Planar Target}
%-----------------------------------------------------------------------------------------------

%-----------------------------------------------------------------------------------------------
\section{Comparison}
%-----------------------------------------------------------------------------------------------

